{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9306806079969019\n",
      "[('The', 'DT'), ('brown', 'JJ'), ('fox', 'NN'), ('is', 'VBZ'), ('quick', 'JJ'), ('and', 'CC'), ('he', 'PRP'), ('is', 'VBZ'), ('jumping', 'VBG'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'JJ'), ('dog', 'VBG')]\n"
     ]
    }
   ],
   "source": [
    "sentence = 'The brown fox is quick and he is jumping over the lazy dog'\n",
    "\n",
    "# recommended tagger based on PTB\n",
    "import nltk\n",
    "tokens = nltk.word_tokenize(sentence)\n",
    "\n",
    "# preparing the data\n",
    "from nltk.corpus import treebank\n",
    "data = treebank.tagged_sents()\n",
    "train_data = data[:3500]\n",
    "test_data = data[3500:]\n",
    "\n",
    "from nltk.classify import NaiveBayesClassifier, MaxentClassifier\n",
    "from nltk.tag.sequential import ClassifierBasedPOSTagger\n",
    "\n",
    "nbt = ClassifierBasedPOSTagger(train=train_data,\n",
    "                               classifier_builder=NaiveBayesClassifier.train)\n",
    "\n",
    "print(nbt.evaluate(test_data))\n",
    "print(nbt.tag(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done !!!!\n"
     ]
    }
   ],
   "source": [
    "main_list = []\n",
    "\n",
    "for path in glob('dataset/TRAIN/*.xml'):\n",
    "    tree = ET.parse(path)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    for s in root.iter('s'):\n",
    "        child_list = []\n",
    "        for child in s.getchildren():\n",
    "            if (child.text != None):\n",
    "                item = (child.text, child.attrib['pos'])\n",
    "            if (len(item) == 2):\n",
    "                child_list.append(item)\n",
    "        \n",
    "        if(child_list):\n",
    "            main_list.append(child_list)\n",
    "\n",
    "print('done !!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done !!!!\n"
     ]
    }
   ],
   "source": [
    "test_list = []\n",
    "\n",
    "for path in glob('dataset/TEST/*.xml'):\n",
    "    tree = ET.parse(path)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    for s in root.iter('s'):\n",
    "        child_list = []\n",
    "        for child in s.getchildren():\n",
    "            if (child.text != None):\n",
    "                item = (child.text, child.attrib['pos'])\n",
    "            if (len(item) == 2):\n",
    "                child_list.append(item)\n",
    "        \n",
    "        if(child_list):\n",
    "            test_list.append(child_list)\n",
    "\n",
    "print('done !!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3500"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4790"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(main_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2395"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8654746011839746\n",
      "[('بریکنگ', 'PN'), ('نیوز', 'PN'), (':', 'PM'), ('بڑا', 'ADJ'), ('فیصلہ', 'NN'), ('آ', 'VB'), ('گیا', 'AA'), ('،', 'PM'), ('پاکستان', 'PN'), ('کو', 'P'), ('عالمی', 'ADJ'), ('عدالت', 'NN'), ('سے', 'SE'), ('بڑی', 'ADJ'), ('خوشخبری', 'ADJ'), ('مل', 'VB'), ('گئی', 'AA')]\n"
     ]
    }
   ],
   "source": [
    "sent = 'بریکنگ نیوز : بڑا فیصلہ آ گیا ، پاکستان کو عالمی عدالت سے بڑی خوشخبری مل گئی'\n",
    "u_tokens = nltk.word_tokenize(sent)\n",
    "\n",
    "nbt_urdu = ClassifierBasedPOSTagger(train=main_list, classifier_builder=NaiveBayesClassifier.train)\n",
    "\n",
    "print(nbt_urdu.evaluate(test_list))\n",
    "print(nbt_urdu.tag(u_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (len(train_urdu[0][0]) == 3):\n",
    "    print(\"true\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
